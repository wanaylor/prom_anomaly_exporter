{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "MLFLOW_SERVER = os.getenv(\"MLFLOW_SERVER\")\n",
    "PROM_SERVER = os.getenv(\"PROM_SERVER\")\n",
    "# The following environment variables are needed for auth to S3\n",
    "#AWS_ACCESS_KEY_ID\n",
    "#AWS_SECRET_ACCESS_KEY\n",
    "#MLFLOW_S3_ENDPOINT_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Network Metrics for few days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_api_client import MetricRangeDataFrame\n",
    "import datetime as dt\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "prom = PrometheusConnect(url=f\"http://{PROM_SERVER}:9090\") # Replace with your Prometheus URL\n",
    "\n",
    "start_time = dt.datetime(2025, 6, 5, 0, 0, 0)\n",
    "end_time = dt.datetime(2025, 6, 10, 0, 0, 0)\n",
    "chunk_size = dt.timedelta(minutes=1) # Optional: for large data ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "def range_query_to_df(metric: str, rate_base: str, start: datetime, end: datetime, date_range_step: str) -> pd.DataFrame:\n",
    "    start_string = start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_string = end.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    prom_query = f'http://{PROM_SERVER}:9090/api/v1/query_range?query=rate({metric}[{rate_base}])&start={start_string}&end={end_string}&step={date_range_step}'\n",
    "    resp = requests.get(prom_query)\n",
    "    data = json.loads(resp.text)\n",
    "    all_data = []\n",
    "    for result in data['data']['result']:\n",
    "        metric_labels = result['metric']\n",
    "        device = metric_labels.get('device', 'unknown')\n",
    "        \n",
    "        for timestamp, value in result['values']:\n",
    "            all_data.append({\n",
    "                'timestamp': pd.to_datetime(timestamp, unit='s'),\n",
    "                'device': device,\n",
    "                'value': float(value)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df.pivot(index='timestamp', columns='device', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node_network_receive_bytes_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_network_receive_bytes_total = range_query_to_df(metric = 'node_network_receive_bytes_total', rate_base = '1m', start = start_time, end = end_time, date_range_step = '60s')\n",
    "node_network_receive_bytes_total = node_network_receive_bytes_total[['br-0c6e79cd156e', 'br-8fbdbc8e9f6a', 'docker0', 'eth0', 'lo']]\n",
    "node_network_receive_bytes_total.columns = ['br-0c6e79cd156e - Rx in', 'br-8fbdbc8e9f6a - Rx in', 'docker0 - Rx in', 'eth0 - Rx in', 'lo - Rx in']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node_network_transmit_bytes_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_network_transmit_bytes_total = range_query_to_df(metric = 'node_network_transmit_bytes_total', rate_base = '1m', start = start_time, end = end_time, date_range_step = '60s')\n",
    "node_network_transmit_bytes_total = node_network_transmit_bytes_total[['br-0c6e79cd156e', 'br-8fbdbc8e9f6a', 'docker0', 'eth0', 'lo']]\n",
    "node_network_transmit_bytes_total.columns = ['br-0c6e79cd156e - Tx out', 'br-8fbdbc8e9f6a - Tx out', 'docker0 - Tx out', 'eth0 - Tx out', 'lo - Tx out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node_network_receive_packets_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_network_receive_packets_total = range_query_to_df(metric = 'node_network_receive_packets_total', rate_base = '1m', start = start_time, end = end_time, date_range_step = '60s')\n",
    "node_network_receive_packets_total = node_network_receive_packets_total[['br-0c6e79cd156e', 'br-8fbdbc8e9f6a', 'docker0', 'eth0', 'lo']]\n",
    "node_network_receive_packets_total.columns = ['br-0c6e79cd156e -  Pck in', 'br-8fbdbc8e9f6a -  Pck in', 'docker0 -  Pck in', 'eth0 -  Pck in', 'lo -  Pck in']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node_network_transmit_packets_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_network_transmit_packets_total = range_query_to_df(metric = 'node_network_transmit_packets_total', rate_base = '1m', start = start_time, end = end_time, date_range_step = '60s')\n",
    "node_network_transmit_packets_total = node_network_transmit_packets_total[['br-0c6e79cd156e', 'br-8fbdbc8e9f6a', 'docker0', 'eth0', 'lo']]\n",
    "node_network_transmit_packets_total.columns = ['br-0c6e79cd156e -  Pck out', 'br-8fbdbc8e9f6a -  Pck out', 'docker0 -  Pck out', 'eth0 -  Pck out', 'lo -  Pck out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.merge(node_network_receive_bytes_total, node_network_transmit_bytes_total, left_index=True, right_index=True)\n",
    "network_df = pd.merge(network_df, node_network_receive_packets_total, left_index=True, right_index=True)\n",
    "network_df = pd.merge(network_df, node_network_transmit_packets_total, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df.drop(columns='timestamp', inplace=True)\n",
    "network_df = network_df[network_df.columns.sort_values()]\n",
    "network_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log an MLFlow Expirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def KL_divergence(a, b):\n",
    "    hist_a = np.histogram(a, bins=200, range=(-1,1.0))[0]\n",
    "    hist_b = np.histogram(b, bins=200, range=(-1,1.0))[0]\n",
    "    hist_b = np.where(hist_b == 0.0, 1e-6, hist_b)\n",
    "    return entropy(hist_a, hist_b)\n",
    "\n",
    "remote_server_uri = f\"http://{MLFLOW_SERVER}:5000\"  # set to your server URI, e.g. http://127.0.0.1:8080\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(\"/Network_Bytes_and_Packets_Isolation_Forest\")\n",
    "mlflow.sklearn.autolog()\n",
    "model_kld_scores = []\n",
    "estimators = [5, 10, 50, 100, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "for estimator in estimators:\n",
    "    with mlflow.start_run(run_name=f'{estimator}'):\n",
    "        kf = KFold()\n",
    "        klds = []\n",
    "        for train_index, test_index in kf.split(network_df):\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test = network_df.iloc[train_index], network_df.iloc[test_index]\n",
    "            clf = IsolationForest(max_samples=estimator, random_state=0)\n",
    "            clf.fit(X_train)\n",
    "            # Use a KL divergence to detect overfitting\n",
    "            pred_train_set = clf.decision_function(X_train)\n",
    "            pred_test_set = clf.decision_function(X_test)\n",
    "            kld = KL_divergence(pred_train_set, pred_test_set)\n",
    "            print(f'kld is {kld}')\n",
    "            klds.append(kld)\n",
    "        print(f'mean of klds for {estimator} estimators is {np.mean(klds)}')\n",
    "        model_kld_scores.append(np.mean(klds))\n",
    "        mlflow.log_metric('average kld', np.mean(klds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize KL over number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=estimators, y=model_kld_scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best number of trees and visualize against traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(max_samples=2000, random_state=0)\n",
    "clf.fit(network_df.values)\n",
    "y_pred = clf.decision_function(network_df.values)\n",
    "fig = px.line(x=network_df.index, y=y_pred)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "# Add traces to subplots\n",
    "fig.add_trace(go.Line(x=network_df.index, y=y_pred, name='anomaly'), row=1, col=1)\n",
    "for column in network_df.columns:\n",
    "    fig.add_trace(go.Line(x=network_df.index, y=network_df[column], name=column), row=2, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title_text=\"Network Anomaly and Traffic\")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prom-anomaly-exporter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
